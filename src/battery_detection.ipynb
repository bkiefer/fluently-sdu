{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, settings\n",
    "settings.update({\"runs_dir\": \"../runs\", \"weights_dir\": \"../weights\", \"datasets_dir\": \"../data/datasets\"})\n",
    "YOLO_try = False\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as functional\n",
    "import copy\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "import open3d as o3d\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import time\n",
    "from matplotlib.lines import Line2D\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1530, 1369])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tot_sum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 126\u001b[0m\n\u001b[1;32m    123\u001b[0m         noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, std, img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img \u001b[38;5;241m+\u001b[39m img \u001b[38;5;241m*\u001b[39m noise\n\u001b[0;32m--> 126\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mCellDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/cells_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[147], line 31\u001b[0m, in \u001b[0;36mCellDatabase.__init__\u001b[0;34m(self, folder_path, jpg_shape, gauss_p, s_and_p_p, speckle_p)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mys\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxs)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 31\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[43mtot_sum\u001b[49m\u001b[38;5;241m/\u001b[39mtot_pxls\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m gauss_p:\n\u001b[1;32m     33\u001b[0m     noisy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_gaussian_noise(x[\u001b[38;5;241m0\u001b[39m], mean(), all_imgs\u001b[38;5;241m.\u001b[39mstd()), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tot_sum' is not defined"
     ]
    }
   ],
   "source": [
    "class CellDatabase(Dataset):\n",
    "    def __init__(self, folder_path, jpg_shape=(1530, 1369), gauss_p=0.8, s_and_p_p=0.8, speckle_p=0.8):\n",
    "        self.xs = []\n",
    "        self.ys = []\n",
    "        if not os.path.exists(folder_path):\n",
    "            raise Exception(\"Folder not found, dataset not created!\")\n",
    "        subdirs = os.listdir(folder_path)\n",
    "        if not ('annotations' in subdirs and 'images' in subdirs):\n",
    "            raise Exception(\"Folder not in right standard (YOLO), dataset not created!\")\n",
    "        annotations = (sorted(os.listdir(os.path.join(folder_path, 'annotations'))))\n",
    "        images = (sorted( os.listdir(os.path.join(folder_path, 'images'))))\n",
    "        for img_path, ann_path in zip(images, annotations):\n",
    "            x = self.padding_img(torchvision.io.read_image(os.path.join(folder_path, 'images', img_path)), jpg_shape, 0)\n",
    "\n",
    "            with open(os.path.join(folder_path, 'annotations', ann_path), \"r\") as file: \n",
    "                labels, boxes = [], []\n",
    "                for line in file:\n",
    "                    content = line.split(' ')\n",
    "                    labels.append(int(content[0]))\n",
    "                    centre_x, centre_y, width, height = [float(element) for element in content[1:]]\n",
    "                    x_min = centre_x - (width / 2)\n",
    "                    y_min = centre_y - (height / 2)\n",
    "                    x_max = centre_x + (width / 2)\n",
    "                    y_max = centre_y + (height / 2)\n",
    "                    boxes.append([x_min, y_min, x_max, y_max])\n",
    "            y = {'labels': torch.tensor(labels, dtype=torch.int64), 'boxes': torch.tensor(boxes, dtype=torch.float32)}\n",
    "            self.xs.append(x)\n",
    "            self.ys.append(y)\n",
    "\n",
    "        print(torch.stack(self.xs).shape)\n",
    "        mean = tot_sum/tot_pxls\n",
    "        if np.random.rand() < gauss_p:\n",
    "            noisy = torch.tensor(self.add_gaussian_noise(x[0], mean(), all_imgs.std()), dtype=torch.float32).unsqueeze(0)\n",
    "            noisy = (noisy - min_val) / (max_val - min_val + 1e-10)\n",
    "            self.xs.append(noisy)\n",
    "            self.ys.append(y)\n",
    "        if np.random.rand() < s_and_p_p:\n",
    "            noisy = torch.tensor(self.add_salt_pepper_noise(x[0]), dtype=torch.float32).unsqueeze(0)\n",
    "            noisy = (noisy - min_val) / (max_val - min_val + 1e-10)\n",
    "            self.xs.append(noisy)\n",
    "            self.ys.append(y)\n",
    "        if np.random.rand() < speckle_p:\n",
    "            noisy = torch.tensor(self.add_speckle_noise(x[0]), dtype=torch.float32).unsqueeze(0)\n",
    "            noisy = (noisy - min_val) / (max_val - min_val + 1e-10)\n",
    "            self.xs.append(noisy)\n",
    "            self.ys.append(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.ys[idx]\n",
    "        x = self.xs[idx]\n",
    "        return x, y\n",
    "\n",
    "    def show_x(self, idx, annotate_ys=True):\n",
    "        if annotate_ys:\n",
    "            self.mark_bb_on_img(self.xs[idx], self.ys[idx])\n",
    "        else:\n",
    "            plt.imshow(self.xs[idx].numpy().transpose(1, 2, 0))\n",
    "        \n",
    "    def print_y(self, idx):\n",
    "        print(df.ys[idx])\n",
    "    \n",
    "    @staticmethod\n",
    "    def padding_img(img, desired_shape, padding_value):\n",
    "        padded_channels = []\n",
    "    \n",
    "        # Calculate padding for height and width\n",
    "        pad_height_top = (desired_shape[0] - img.shape[1]) // 2  # Padding at the top\n",
    "        pad_height_bottom = desired_shape[0] - img.shape[1] - pad_height_top  # Padding at the bottom\n",
    "        pad_width_left = (desired_shape[1] - img.shape[2]) // 2  # Padding on the left\n",
    "        pad_width_right = desired_shape[1] - img.shape[2] - pad_width_left  # Padding on the right\n",
    "        \n",
    "        for channel in img:\n",
    "            # Padding along height (top and bottom)\n",
    "            padded_channel = torch.nn.functional.pad(channel, (pad_width_left, pad_width_right, pad_height_top, pad_height_bottom), value=padding_value)\n",
    "            \n",
    "            # Add the padded channel to the list\n",
    "            padded_channels.append(padded_channel)\n",
    "        \n",
    "        # Stack all padded channels into one image tensor\n",
    "        padded_img = torch.stack(padded_channels)\n",
    "        \n",
    "        return padded_img\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def mark_bb_on_img(x, y):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        colors = ['red']\n",
    "        legend_handle = []\n",
    "        for i, clr  in enumerate(colors):\n",
    "            legend_handle.append(Line2D([0], [0], color=clr, marker='s', label=str(i), markersize=5, linestyle='none'))\n",
    "        ax = plt.subplot(1, 2, 1)\n",
    "        for j, (label, box) in enumerate(zip(y['labels'], y['boxes'])):\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            ax.add_patch(patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor=colors[label], facecolor='none'))\n",
    "        plt.legend(handles=legend_handle, bbox_to_anchor=(1, 1))\n",
    "        plt.imshow(x.numpy().transpose(1, 2, 0))\n",
    "          \n",
    "    @staticmethod\n",
    "    def normalize_img(img, min_value, max_value):\n",
    "        return (img - min_value) / (max_value - min_value + 1e-10)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_gaussian_noise(image, mean, std):\n",
    "        return image + np.random.normal(mean, std, image.shape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_salt_pepper_noise(image, prob=0.01):\n",
    "        noisy = copy.deepcopy(image)\n",
    "        noisy = np.array(noisy)\n",
    "        noise_prob = np.random.rand(noisy.shape[0], noisy.shape[1])\n",
    "        noisy[noise_prob < prob / 2] = noisy.min()  # Pepper (black)\n",
    "        noisy[noise_prob > 1 - prob / 2] = noisy.max()  # Salt (white)\n",
    "        return noisy\n",
    "\n",
    "    @staticmethod\n",
    "    def add_speckle_noise(image, std=0.2):\n",
    "        img = copy.deepcopy(image)\n",
    "        img = np.array(img)\n",
    "        noise = np.random.normal(0, std, img.shape)\n",
    "        return img + img * noise\n",
    "    \n",
    "df = CellDatabase(\"../data/cells_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Try (on hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YOLO_try:\n",
    "    # Create a new YOLO model from scratch\n",
    "    # model = YOLO(\"yolo11n.yaml\")\n",
    "\n",
    "    # Load a pretrained YOLO model (recommended for training)\n",
    "    model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "\n",
    "    # Train the model using the 'coco8.yaml' dataset for 3 epochs\n",
    "    results = model.train(data=\"coco8.yaml\", epochs=3)\n",
    "\n",
    "    img = cv2.imread(\"../data/NMC21700-from-top.jpg\")\n",
    "    print(img.shape)\n",
    "    results = model.predict(source=img, save=True)\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Faster R-CNN model with a ResNet-50 backbone\n",
    "model = fasterrcnn_resnet50_fpn(weights=None)\n",
    "\n",
    "# Number of classes (your dataset classes + 1 for background)\n",
    "num_classes = 2  # For example, 2 classes + background\n",
    "\n",
    "# Get the number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# Replace the head of the model with a new one (for the number of classes in your dataset)\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
